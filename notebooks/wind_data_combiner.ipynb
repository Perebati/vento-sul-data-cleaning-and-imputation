{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa926e1a",
   "metadata": {},
   "source": [
    "# Wind Data Combiner\n",
    "\n",
    "Este notebook combina os dados de três arquivos de vento (Dir.txt, W.txt, WS.txt) em um único dataset regularizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75350be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "385b71f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório de dados brutos: ../raw_data\n",
      "Diretório de saída: ..\n",
      "Arquivos a processar: ['Dir.txt', 'W.txt', 'WS.txt']\n"
     ]
    }
   ],
   "source": [
    "# Definir caminhos dos arquivos\n",
    "raw_data_path = Path('../raw_data')\n",
    "output_path = Path('../')\n",
    "\n",
    "# Lista dos arquivos a serem processados\n",
    "files_to_process = ['Dir.txt', 'W.txt', 'WS.txt']\n",
    "\n",
    "print(f\"Diretório de dados brutos: {raw_data_path}\")\n",
    "print(f\"Diretório de saída: {output_path}\")\n",
    "print(f\"Arquivos a processar: {files_to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7fbda75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Função de leitura definida\n"
     ]
    }
   ],
   "source": [
    "# Função para ler e processar cada arquivo\n",
    "def read_wind_data(file_path, prefix):\n",
    "    \"\"\"\n",
    "    Lê arquivo de dados de vento e renomeia colunas com prefixo.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Caminho para o arquivo\n",
    "        prefix: Prefixo para as colunas (Dir, W, WS)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com colunas renomeadas\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, sep=';', encoding='utf-8')\n",
    "    \n",
    "    # Converter coluna DT para datetime\n",
    "    df['DT'] = pd.to_datetime(df['DT'])\n",
    "    \n",
    "    # Renomear colunas (exceto DT) com o prefixo\n",
    "    column_mapping = {col: f\"{prefix}-{col}\" for col in df.columns if col != 'DT'}\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    print(f\"Arquivo {file_path.name} carregado: {len(df)} registros\")\n",
    "    print(f\"Período: {df['DT'].min()} até {df['DT'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Função de leitura definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce76e638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Dir.txt carregado: 41786 registros\n",
      "Período: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "✓ Dir.txt processado\n",
      "Arquivo W.txt carregado: 41786 registros\n",
      "Período: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "✓ W.txt processado\n",
      "Arquivo WS.txt carregado: 41786 registros\n",
      "Período: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "✓ WS.txt processado\n",
      "\n",
      "Total de arquivos carregados: 3\n",
      "Arquivo WS.txt carregado: 41786 registros\n",
      "Período: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "✓ WS.txt processado\n",
      "\n",
      "Total de arquivos carregados: 3\n"
     ]
    }
   ],
   "source": [
    "# Carregar todos os arquivos\n",
    "dataframes = []\n",
    "\n",
    "for file_name in files_to_process:\n",
    "    file_path = raw_data_path / file_name\n",
    "    prefix = file_name.replace('.txt', '')  # Remove extensão para usar como prefixo\n",
    "    \n",
    "    if file_path.exists():\n",
    "        df = read_wind_data(file_path, prefix)\n",
    "        dataframes.append(df)\n",
    "        print(f\"✓ {file_name} processado\")\n",
    "    else:\n",
    "        print(f\"✗ Arquivo {file_name} não encontrado\")\n",
    "\n",
    "print(f\"\\nTotal de arquivos carregados: {len(dataframes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc2d4670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset combinado criado com 42524 registros\n",
      "Colunas no dataset: 79\n",
      "Primeiras colunas: ['DT', 'Dir-SODAR-30', 'Dir-SODAR-40', 'Dir-SODAR-50', 'Dir-SODAR-60', 'Dir-SODAR-70', 'Dir-SODAR-80', 'Dir-SODAR-90', 'Dir-SODAR-100', 'Dir-SODAR-110']\n"
     ]
    }
   ],
   "source": [
    "# Combinar todos os DataFrames usando merge na coluna DT\n",
    "if len(dataframes) > 0:\n",
    "    # Começar com o primeiro DataFrame\n",
    "    combined_df = dataframes[0]\n",
    "    \n",
    "    # Fazer merge com os demais\n",
    "    for df in dataframes[1:]:\n",
    "        combined_df = pd.merge(combined_df, df, on='DT', how='outer')\n",
    "    \n",
    "    print(f\"Dataset combinado criado com {len(combined_df)} registros\")\n",
    "    print(f\"Colunas no dataset: {len(combined_df.columns)}\")\n",
    "    print(f\"Primeiras colunas: {list(combined_df.columns[:10])}\")\n",
    "else:\n",
    "    print(\"Nenhum arquivo foi carregado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69c15967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset filtrado criado com 42524 registros\n",
      "Colunas selecionadas: 33 (excluindo timestamp)\n",
      "Alturas SODAR incluídas: 40m até 140m\n"
     ]
    }
   ],
   "source": [
    "# Filtrar apenas as colunas de SODAR-40 até SODAR-140\n",
    "# Primeiro renomear DT para timestamp\n",
    "combined_df = combined_df.rename(columns={'DT': 'timestamp'})\n",
    "\n",
    "# Selecionar colunas timestamp e SODAR-40 até SODAR-140\n",
    "sodar_columns = ['timestamp']\n",
    "for height in range(40, 150, 10):  # 40, 50, 60, ..., 140\n",
    "    for prefix in ['Dir', 'W', 'WS']:\n",
    "        col_name = f\"{prefix}-SODAR-{height}\"\n",
    "        if col_name in combined_df.columns:\n",
    "            sodar_columns.append(col_name)\n",
    "\n",
    "# Criar DataFrame filtrado\n",
    "wind_data = combined_df[sodar_columns].copy()\n",
    "\n",
    "print(f\"Dataset filtrado criado com {len(wind_data)} registros\")\n",
    "print(f\"Colunas selecionadas: {len(wind_data.columns) - 1} (excluindo timestamp)\")\n",
    "print(f\"Alturas SODAR incluídas: 40m até 140m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b430709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Estrutura do Dataset Atual ===\n",
      "Forma: (42524, 34)\n",
      "\n",
      "Primeiros e últimos timestamps:\n",
      "Início: 2021-11-10 17:20:00\n",
      "Fim: 2022-10-09 08:30:00\n",
      "\n",
      "Verificação de valores nulos por coluna:\n",
      "timestamp         0\n",
      "Dir-SODAR-40    487\n",
      "W-SODAR-40      434\n",
      "WS-SODAR-40     487\n",
      "Dir-SODAR-50    474\n",
      "W-SODAR-50      489\n",
      "WS-SODAR-50     474\n",
      "Dir-SODAR-60    486\n",
      "W-SODAR-60      536\n",
      "WS-SODAR-60     486\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar estrutura atual dos dados\n",
    "print(\"=== Estrutura do Dataset Atual ===\")\n",
    "print(f\"Forma: {wind_data.shape}\")\n",
    "print(f\"\\nPrimeiros e últimos timestamps:\")\n",
    "print(f\"Início: {wind_data['timestamp'].min()}\")\n",
    "print(f\"Fim: {wind_data['timestamp'].max()}\")\n",
    "print(f\"\\nVerificação de valores nulos por coluna:\")\n",
    "print(wind_data.isnull().sum().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fa3d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Regularização da Série Temporal ===\n",
      "Duplicatas removidas: 833\n",
      "Período original: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "Registros originais: 41691\n",
      "Timestamps esperados (10min): 47900\n",
      "Timestamps faltantes: 6209\n"
     ]
    }
   ],
   "source": [
    "# Regularizar série temporal - criar índice completo com intervalos de 10 minutos\n",
    "print(\"=== Regularização da Série Temporal ===\")\n",
    "\n",
    "# Ordenar por timestamp\n",
    "wind_data = wind_data.sort_values('timestamp')\n",
    "\n",
    "# Remover duplicatas de timestamp\n",
    "duplicates_before = wind_data.duplicated(subset=['timestamp']).sum()\n",
    "wind_data = wind_data.drop_duplicates(subset=['timestamp'])\n",
    "print(f\"Duplicatas removidas: {duplicates_before}\")\n",
    "\n",
    "# Criar série temporal completa com intervalos de 10 minutos\n",
    "start_time = wind_data['timestamp'].min()\n",
    "end_time = wind_data['timestamp'].max()\n",
    "\n",
    "# Gerar todos os timestamps de 10 em 10 minutos\n",
    "complete_timeline = pd.date_range(start=start_time, end=end_time, freq='10min')\n",
    "complete_df = pd.DataFrame({'timestamp': complete_timeline})\n",
    "\n",
    "print(f\"Período original: {start_time} até {end_time}\")\n",
    "print(f\"Registros originais: {len(wind_data)}\")\n",
    "print(f\"Timestamps esperados (10min): {len(complete_timeline)}\")\n",
    "print(f\"Timestamps faltantes: {len(complete_timeline) - len(wind_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85de7bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Regularizado ===\n",
      "Forma final: (47900, 34)\n",
      "Total de timestamps: 47900\n",
      "Timestamps únicos: 47900\n",
      "Duplicatas finais: 0\n",
      "\n",
      "Estatísticas de valores faltantes:\n",
      "Colunas com dados faltantes: 33\n",
      "Total de valores NaN: 233444\n"
     ]
    }
   ],
   "source": [
    "# Fazer merge para preencher timestamps faltantes com NaN\n",
    "wind_data_regularized = pd.merge(complete_df, wind_data, on='timestamp', how='left')\n",
    "\n",
    "print(\"=== Dataset Regularizado ===\")\n",
    "print(f\"Forma final: {wind_data_regularized.shape}\")\n",
    "print(f\"Total de timestamps: {len(wind_data_regularized)}\")\n",
    "print(f\"Timestamps únicos: {wind_data_regularized['timestamp'].nunique()}\")\n",
    "\n",
    "# Verificar se há duplicatas finais\n",
    "final_duplicates = wind_data_regularized.duplicated(subset=['timestamp']).sum()\n",
    "print(f\"Duplicatas finais: {final_duplicates}\")\n",
    "\n",
    "# Estatísticas de valores faltantes\n",
    "missing_stats = wind_data_regularized.isnull().sum()\n",
    "print(f\"\\nEstatísticas de valores faltantes:\")\n",
    "print(f\"Colunas com dados faltantes: {(missing_stats > 0).sum()}\")\n",
    "print(f\"Total de valores NaN: {missing_stats.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8c3cf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reorganização e Renomeação das Colunas ===\n",
      "Colunas renomeadas: 33\n",
      "Ordem das colunas reorganizada:\n",
      "  - Velocidade (WS): ws40 até ws140\n",
      "  - Vento vertical (W): v40 até v140\n",
      "  - Direção (Dir): dir40 até dir140\n",
      "Total de colunas ordenadas: 34\n"
     ]
    }
   ],
   "source": [
    "# Reorganizar e renomear colunas conforme especificado\n",
    "print(\"=== Reorganização e Renomeação das Colunas ===\")\n",
    "\n",
    "# Primeiro, criar mapeamento para renomear colunas\n",
    "column_mapping = {}\n",
    "for height in range(40, 150, 10):  # 40, 50, 60, ..., 140\n",
    "    # WS-SODAR-XX -> wsXX\n",
    "    old_ws = f\"WS-SODAR-{height}\"\n",
    "    new_ws = f\"ws{height}\"\n",
    "    if old_ws in wind_data_regularized.columns:\n",
    "        column_mapping[old_ws] = new_ws\n",
    "    \n",
    "    # W-SODAR-XX -> vXX (vento vertical)\n",
    "    old_w = f\"W-SODAR-{height}\"\n",
    "    new_w = f\"v{height}\"\n",
    "    if old_w in wind_data_regularized.columns:\n",
    "        column_mapping[old_w] = new_w\n",
    "    \n",
    "    # Dir-SODAR-XX -> dirXX\n",
    "    old_dir = f\"Dir-SODAR-{height}\"\n",
    "    new_dir = f\"dir{height}\"\n",
    "    if old_dir in wind_data_regularized.columns:\n",
    "        column_mapping[old_dir] = new_dir\n",
    "\n",
    "# Aplicar renomeação\n",
    "wind_data_regularized = wind_data_regularized.rename(columns=column_mapping)\n",
    "\n",
    "print(f\"Colunas renomeadas: {len(column_mapping)}\")\n",
    "\n",
    "# Organizar ordem das colunas: timestamp, ws40-ws140, v40-v140, dir40-dir140\n",
    "ordered_columns = ['timestamp']\n",
    "\n",
    "# Adicionar colunas WS (velocidade do vento)\n",
    "for height in range(40, 150, 10):\n",
    "    ws_col = f\"ws{height}\"\n",
    "    if ws_col in wind_data_regularized.columns:\n",
    "        ordered_columns.append(ws_col)\n",
    "\n",
    "# Adicionar colunas W (vento vertical)\n",
    "for height in range(40, 150, 10):\n",
    "    v_col = f\"v{height}\"\n",
    "    if v_col in wind_data_regularized.columns:\n",
    "        ordered_columns.append(v_col)\n",
    "\n",
    "# Adicionar colunas Dir (direção)\n",
    "for height in range(40, 150, 10):\n",
    "    dir_col = f\"dir{height}\"\n",
    "    if dir_col in wind_data_regularized.columns:\n",
    "        ordered_columns.append(dir_col)\n",
    "\n",
    "# Reordenar o DataFrame\n",
    "wind_data_regularized = wind_data_regularized[ordered_columns]\n",
    "\n",
    "print(f\"Ordem das colunas reorganizada:\")\n",
    "print(f\"  - Velocidade (WS): ws40 até ws140\")\n",
    "print(f\"  - Vento vertical (W): v40 até v140\") \n",
    "print(f\"  - Direção (Dir): dir40 até dir140\")\n",
    "print(f\"Total de colunas ordenadas: {len(ordered_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d391f283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Amostra do Dataset Final ===\n",
      "Primeiras 5 linhas:\n",
      "            timestamp  ws40  ws50  ws60  ws70  ws80  ws90  ws100  ws110  \\\n",
      "0 2021-11-10 17:20:00  5.03  5.53  5.54  5.66  5.74  5.82   5.83   5.79   \n",
      "1 2021-11-10 17:30:00  4.94  5.30  5.29  5.72  5.87  5.98   5.99   6.06   \n",
      "2 2021-11-10 17:40:00  4.44  5.96  5.66  6.44  6.55  6.61   6.67   6.67   \n",
      "3 2021-11-10 17:50:00  4.28  4.91  5.04  5.80  5.95  6.03   6.15   6.17   \n",
      "4 2021-11-10 18:00:00  4.53  5.02  4.66  5.52  5.62  5.70   5.90   5.93   \n",
      "\n",
      "   ws120  ...  dir50  dir60  dir70  dir80  dir90  dir100  dir110  dir120  \\\n",
      "0   5.71  ...   30.5   29.2   31.4   31.3   32.3    33.3    33.6    32.8   \n",
      "1   6.18  ...   37.7   35.0   34.7   34.8   35.6    36.4    37.6    38.2   \n",
      "2   6.63  ...   42.7   41.3   42.0   43.1   43.0    43.3    42.9    43.2   \n",
      "3   6.24  ...   44.3   45.7   43.7   45.0   45.7    46.8    46.2    46.3   \n",
      "4   6.15  ...   49.5   44.6   43.6   45.1   44.4    42.5    40.2    39.0   \n",
      "\n",
      "   dir130  dir140  \n",
      "0    31.4    30.8  \n",
      "1    38.4    38.8  \n",
      "2    42.6    42.0  \n",
      "3    45.5    44.5  \n",
      "4    39.1    39.3  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "\n",
      "Últimas 5 linhas:\n",
      "                timestamp   ws40   ws50   ws60   ws70   ws80   ws90  ws100  \\\n",
      "47895 2022-10-09 07:50:00   9.27  10.07   9.90   9.52  10.03  10.13  10.34   \n",
      "47896 2022-10-09 08:00:00  11.20  11.74  10.98  10.91  11.18  11.46  12.05   \n",
      "47897 2022-10-09 08:10:00  12.00  12.28  13.10  13.41  13.65  13.97  14.68   \n",
      "47898 2022-10-09 08:20:00  11.68  11.93  11.07  13.01  13.06  12.88  12.71   \n",
      "47899 2022-10-09 08:30:00   8.84   9.83  10.27   9.94   9.92  10.30  10.86   \n",
      "\n",
      "       ws110  ws120  ...  dir50  dir60  dir70  dir80  dir90  dir100  dir110  \\\n",
      "47895  10.48  10.63  ...   89.8   90.2   93.2   92.0   90.9    90.7    91.1   \n",
      "47896  12.14  12.35  ...   88.5   90.2   88.7   90.3   89.6    89.0    87.8   \n",
      "47897  14.78  15.71  ...   87.6   85.1   86.9   84.7   81.9    81.3    81.4   \n",
      "47898  11.65  10.93  ...   78.6   75.6   77.3   78.0   78.2    77.3    76.0   \n",
      "47899  11.11  11.59  ...   84.5   86.8   86.3   84.2   83.5    83.5    83.6   \n",
      "\n",
      "       dir120  dir130  dir140  \n",
      "47895    92.0    93.1    92.7  \n",
      "47896    88.8    87.9    88.1  \n",
      "47897    82.3    80.8    79.6  \n",
      "47898    73.5    74.0    72.8  \n",
      "47899    83.3    83.9    83.3  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "\n",
      "Nomes das colunas reorganizadas:\n",
      "Colunas: ['timestamp', 'ws40', 'ws50', 'ws60', 'ws70', 'ws80', 'ws90', 'ws100', 'ws110', 'ws120', 'ws130', 'ws140', 'v40', 'v50', 'v60', 'v70', 'v80', 'v90', 'v100', 'v110', 'v120', 'v130', 'v140', 'dir40', 'dir50', 'dir60', 'dir70', 'dir80', 'dir90', 'dir100', 'dir110', 'dir120', 'dir130', 'dir140']\n",
      "\n",
      "Info do dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47900 entries, 0 to 47899\n",
      "Data columns (total 34 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   timestamp  47900 non-null  datetime64[ns]\n",
      " 1   ws40       41204 non-null  float64       \n",
      " 2   ws50       41217 non-null  float64       \n",
      " 3   ws60       41205 non-null  float64       \n",
      " 4   ws70       41176 non-null  float64       \n",
      " 5   ws80       41118 non-null  float64       \n",
      " 6   ws90       41068 non-null  float64       \n",
      " 7   ws100      40979 non-null  float64       \n",
      " 8   ws110      40842 non-null  float64       \n",
      " 9   ws120      40639 non-null  float64       \n",
      " 10  ws130      40389 non-null  float64       \n",
      " 11  ws140      40056 non-null  float64       \n",
      " 12  v40        41257 non-null  float64       \n",
      " 13  v50        41202 non-null  float64       \n",
      " 14  v60        41155 non-null  float64       \n",
      " 15  v70        41041 non-null  float64       \n",
      " 16  v80        40980 non-null  float64       \n",
      " 17  v90        40870 non-null  float64       \n",
      " 18  v100       40708 non-null  float64       \n",
      " 19  v110       40494 non-null  float64       \n",
      " 20  v120       40235 non-null  float64       \n",
      " 21  v130       39934 non-null  float64       \n",
      " 22  v140       39594 non-null  float64       \n",
      " 23  dir40      41204 non-null  float64       \n",
      " 24  dir50      41217 non-null  float64       \n",
      " 25  dir60      41205 non-null  float64       \n",
      " 26  dir70      41176 non-null  float64       \n",
      " 27  dir80      41118 non-null  float64       \n",
      " 28  dir90      41068 non-null  float64       \n",
      " 29  dir100     40979 non-null  float64       \n",
      " 30  dir110     40842 non-null  float64       \n",
      " 31  dir120     40639 non-null  float64       \n",
      " 32  dir130     40389 non-null  float64       \n",
      " 33  dir140     40056 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(33)\n",
      "memory usage: 12.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Exibir amostra dos dados finais\n",
    "print(\"=== Amostra do Dataset Final ===\")\n",
    "print(\"Primeiras 5 linhas:\")\n",
    "print(wind_data_regularized.head())\n",
    "print(\"\\nÚltimas 5 linhas:\")\n",
    "print(wind_data_regularized.tail())\n",
    "print(f\"\\nNomes das colunas reorganizadas:\")\n",
    "print(f\"Colunas: {list(wind_data_regularized.columns)}\")\n",
    "print(\"\\nInfo do dataset:\")\n",
    "print(wind_data_regularized.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b5fa174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Salvo ===\n",
      "Arquivo: ../wind_data.csv\n",
      "Tamanho: 47900 registros\n",
      "Colunas: 34\n",
      "Período: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "✓ Arquivo criado com sucesso (7.75 MB)\n"
     ]
    }
   ],
   "source": [
    "# Salvar o dataset regularizado\n",
    "output_file = output_path / 'wind_data.csv'\n",
    "\n",
    "# Salvar o arquivo\n",
    "wind_data_regularized.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"=== Dataset Salvo ===\")\n",
    "print(f\"Arquivo: {output_file}\")\n",
    "print(f\"Tamanho: {len(wind_data_regularized)} registros\")\n",
    "print(f\"Colunas: {len(wind_data_regularized.columns)}\")\n",
    "print(f\"Período: {wind_data_regularized['timestamp'].min()} até {wind_data_regularized['timestamp'].max()}\")\n",
    "\n",
    "# Verificar se arquivo foi criado\n",
    "if output_file.exists():\n",
    "    file_size = output_file.stat().st_size / (1024 * 1024)  # MB\n",
    "    print(f\"✓ Arquivo criado com sucesso ({file_size:.2f} MB)\")\n",
    "else:\n",
    "    print(\"✗ Erro ao criar arquivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7848a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMO DO PROCESSAMENTO ===\n",
      "\n",
      "1. Arquivos processados: Dir.txt, W.txt, WS.txt\n",
      "2. Dataset combinado: wind_data.csv\n",
      "3. Período de dados: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "4. Intervalo: 10 minutos\n",
      "5. Total de registros: 47,900\n",
      "6. Colunas de dados: 33 (alturas 40m até 140m)\n",
      "7. Duplicatas removidas: 833\n",
      "8. Timestamps adicionados: 7042\n",
      "\n",
      "9. Reorganização das colunas:\n",
      "   - Velocidade do vento (WS): ws40, ws50, ..., ws140\n",
      "   - Vento vertical (W): v40, v50, ..., v140\n",
      "   - Direção (Dir): dir40, dir50, ..., dir140\n",
      "10. Renomeação aplicada:\n",
      "   - 'WS-SODAR-XX' → 'wsXX'\n",
      "   - 'W-SODAR-XX' → 'vXX'\n",
      "   - 'Dir-SODAR-XX' → 'dirXX'\n",
      "\n",
      "✓ Processamento concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Resumo final do processamento\n",
    "print(\"=== RESUMO DO PROCESSAMENTO ===\")\n",
    "print(f\"\\n1. Arquivos processados: {', '.join(files_to_process)}\")\n",
    "print(f\"2. Dataset combinado: wind_data.csv\")\n",
    "print(f\"3. Período de dados: {wind_data_regularized['timestamp'].min()} até {wind_data_regularized['timestamp'].max()}\")\n",
    "print(f\"4. Intervalo: 10 minutos\")\n",
    "print(f\"5. Total de registros: {len(wind_data_regularized):,}\")\n",
    "print(f\"6. Colunas de dados: {len(wind_data_regularized.columns) - 1} (alturas 40m até 140m)\")\n",
    "print(f\"7. Duplicatas removidas: {duplicates_before}\")\n",
    "print(f\"8. Timestamps adicionados: {len(complete_timeline) - len(wind_data) + duplicates_before}\")\n",
    "print(f\"\\n9. Reorganização das colunas:\")\n",
    "print(f\"   - Velocidade do vento (WS): ws40, ws50, ..., ws140\")\n",
    "print(f\"   - Vento vertical (W): v40, v50, ..., v140\")\n",
    "print(f\"   - Direção (Dir): dir40, dir50, ..., dir140\")\n",
    "print(f\"10. Renomeação aplicada:\")\n",
    "print(f\"   - 'WS-SODAR-XX' → 'wsXX'\")\n",
    "print(f\"   - 'W-SODAR-XX' → 'vXX'\")\n",
    "print(f\"   - 'Dir-SODAR-XX' → 'dirXX'\")\n",
    "print(f\"\\n✓ Processamento concluído com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
