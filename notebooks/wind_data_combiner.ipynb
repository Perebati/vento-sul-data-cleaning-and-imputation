{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa926e1a",
   "metadata": {},
   "source": [
    "# Wind Data Combiner\n",
    "\n",
    "Este notebook combina os dados de três arquivos de vento (Dir.txt, W.txt, WS.txt) em um único dataset regularizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75350be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385b71f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório de dados brutos: ../raw_data\n",
      "Diretório de saída: ..\n",
      "Arquivos a processar: ['Dir.txt', 'W.txt', 'WS.txt']\n"
     ]
    }
   ],
   "source": [
    "# Definir caminhos dos arquivos\n",
    "raw_data_path = Path('../raw_data')\n",
    "output_path = Path('../')\n",
    "\n",
    "# Lista dos arquivos a serem processados\n",
    "files_to_process = ['Dir.txt', 'W.txt', 'WS.txt']\n",
    "\n",
    "print(f\"Diretório de dados brutos: {raw_data_path}\")\n",
    "print(f\"Diretório de saída: {output_path}\")\n",
    "print(f\"Arquivos a processar: {files_to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7fbda75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Função de leitura definida\n"
     ]
    }
   ],
   "source": [
    "# Função para ler e processar cada arquivo\n",
    "def read_wind_data(file_path, prefix):\n",
    "    \"\"\"\n",
    "    Lê arquivo de dados de vento e renomeia colunas com prefixo.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Caminho para o arquivo\n",
    "        prefix: Prefixo para as colunas (Dir, W, WS)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com colunas renomeadas\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, sep=';', encoding='utf-8')\n",
    "    \n",
    "    # Converter coluna DT para datetime\n",
    "    df['DT'] = pd.to_datetime(df['DT'])\n",
    "    \n",
    "    # Renomear colunas (exceto DT) com o prefixo\n",
    "    column_mapping = {col: f\"{prefix}-{col}\" for col in df.columns if col != 'DT'}\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    print(f\"Arquivo {file_path.name} carregado: {len(df)} registros\")\n",
    "    print(f\"Período: {df['DT'].min()} até {df['DT'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Função de leitura definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce76e638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Dir.txt carregado: 41786 registros\n",
      "Período: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "✓ Dir.txt processado\n",
      "Arquivo W.txt carregado: 41786 registros\n",
      "Período: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "✓ W.txt processado\n",
      "Arquivo WS.txt carregado: 41786 registros\n",
      "Período: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "✓ WS.txt processado\n",
      "\n",
      "Total de arquivos carregados: 3\n"
     ]
    }
   ],
   "source": [
    "# Carregar todos os arquivos\n",
    "dataframes = []\n",
    "\n",
    "for file_name in files_to_process:\n",
    "    file_path = raw_data_path / file_name\n",
    "    prefix = file_name.replace('.txt', '')  # Remove extensão para usar como prefixo\n",
    "    \n",
    "    if file_path.exists():\n",
    "        df = read_wind_data(file_path, prefix)\n",
    "        dataframes.append(df)\n",
    "        print(f\"✓ {file_name} processado\")\n",
    "    else:\n",
    "        print(f\"✗ Arquivo {file_name} não encontrado\")\n",
    "\n",
    "print(f\"\\nTotal de arquivos carregados: {len(dataframes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc2d4670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset combinado criado com 42524 registros\n",
      "Colunas no dataset: 79\n",
      "Primeiras colunas: ['DT', 'Dir-SODAR-30', 'Dir-SODAR-40', 'Dir-SODAR-50', 'Dir-SODAR-60', 'Dir-SODAR-70', 'Dir-SODAR-80', 'Dir-SODAR-90', 'Dir-SODAR-100', 'Dir-SODAR-110']\n"
     ]
    }
   ],
   "source": [
    "# Combinar todos os DataFrames usando merge na coluna DT\n",
    "if len(dataframes) > 0:\n",
    "    # Começar com o primeiro DataFrame\n",
    "    combined_df = dataframes[0]\n",
    "    \n",
    "    # Fazer merge com os demais\n",
    "    for df in dataframes[1:]:\n",
    "        combined_df = pd.merge(combined_df, df, on='DT', how='outer')\n",
    "    \n",
    "    print(f\"Dataset combinado criado com {len(combined_df)} registros\")\n",
    "    print(f\"Colunas no dataset: {len(combined_df.columns)}\")\n",
    "    print(f\"Primeiras colunas: {list(combined_df.columns[:10])}\")\n",
    "else:\n",
    "    print(\"Nenhum arquivo foi carregado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c15967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset filtrado criado com 42524 registros\n",
      "Colunas selecionadas: 33 (excluindo timestamp)\n",
      "Alturas SODAR incluídas: 40m até 140m\n"
     ]
    }
   ],
   "source": [
    "# Filtrar apenas as colunas de SODAR-40 até SODAR-140\n",
    "# Primeiro renomear DT para timestamp\n",
    "combined_df = combined_df.rename(columns={'DT': 'timestamp'})\n",
    "\n",
    "# Selecionar colunas timestamp e SODAR-40 até SODAR-140\n",
    "sodar_columns = ['timestamp']\n",
    "for height in range(40, 150, 10):  # 40, 50, 60, ..., 140\n",
    "    for prefix in ['Dir', 'W', 'WS']:\n",
    "        col_name = f\"{prefix}-SODAR-{height}\"\n",
    "        if col_name in combined_df.columns:\n",
    "            sodar_columns.append(col_name)\n",
    "\n",
    "# Criar DataFrame filtrado\n",
    "wind_data = combined_df[sodar_columns].copy()\n",
    "\n",
    "print(f\"Dataset filtrado criado com {len(wind_data)} registros\")\n",
    "print(f\"Colunas selecionadas: {len(wind_data.columns) - 1} (excluindo timestamp)\")\n",
    "print(f\"Alturas SODAR incluídas: 40m até 140m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b430709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Estrutura do Dataset Atual ===\n",
      "Forma: (42524, 34)\n",
      "\n",
      "Primeiros e últimos timestamps:\n",
      "Início: 2021-11-10 17:20:00\n",
      "Fim: 2022-10-09 08:30:00\n",
      "\n",
      "Verificação de valores nulos por coluna:\n",
      "timestamp         0\n",
      "Dir-SODAR-40    487\n",
      "W-SODAR-40      434\n",
      "WS-SODAR-40     487\n",
      "Dir-SODAR-50    474\n",
      "W-SODAR-50      489\n",
      "WS-SODAR-50     474\n",
      "Dir-SODAR-60    486\n",
      "W-SODAR-60      536\n",
      "WS-SODAR-60     486\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar estrutura atual dos dados\n",
    "print(\"=== Estrutura do Dataset Atual ===\")\n",
    "print(f\"Forma: {wind_data.shape}\")\n",
    "print(f\"\\nPrimeiros e últimos timestamps:\")\n",
    "print(f\"Início: {wind_data['timestamp'].min()}\")\n",
    "print(f\"Fim: {wind_data['timestamp'].max()}\")\n",
    "print(f\"\\nVerificação de valores nulos por coluna:\")\n",
    "print(wind_data.isnull().sum().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa3d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Regularização da Série Temporal ===\n",
      "Duplicatas removidas: 833\n",
      "Período original: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "Registros originais: 41691\n",
      "Timestamps esperados (10min): 47900\n",
      "Timestamps faltantes: 6209\n"
     ]
    }
   ],
   "source": [
    "# Regularizar série temporal - criar índice completo com intervalos de 10 minutos\n",
    "print(\"=== Regularização da Série Temporal ===\")\n",
    "\n",
    "# Ordenar por timestamp\n",
    "wind_data = wind_data.sort_values('timestamp')\n",
    "\n",
    "# Remover duplicatas de timestamp\n",
    "duplicates_before = wind_data.duplicated(subset=['timestamp']).sum()\n",
    "wind_data = wind_data.drop_duplicates(subset=['timestamp'])\n",
    "print(f\"Duplicatas removidas: {duplicates_before}\")\n",
    "\n",
    "# Criar série temporal completa com intervalos de 10 minutos\n",
    "start_time = wind_data['timestamp'].min()\n",
    "end_time = wind_data['timestamp'].max()\n",
    "\n",
    "# Gerar todos os timestamps de 10 em 10 minutos\n",
    "complete_timeline = pd.date_range(start=start_time, end=end_time, freq='10min')\n",
    "complete_df = pd.DataFrame({'timestamp': complete_timeline})\n",
    "\n",
    "print(f\"Período original: {start_time} até {end_time}\")\n",
    "print(f\"Registros originais: {len(wind_data)}\")\n",
    "print(f\"Timestamps esperados (10min): {len(complete_timeline)}\")\n",
    "print(f\"Timestamps faltantes: {len(complete_timeline) - len(wind_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85de7bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Regularizado ===\n",
      "Forma final: (47900, 34)\n",
      "Total de timestamps: 47900\n",
      "Timestamps únicos: 47900\n",
      "Duplicatas finais: 0\n",
      "\n",
      "Estatísticas de valores faltantes:\n",
      "Colunas com dados faltantes: 33\n",
      "Total de valores NaN: 233444\n"
     ]
    }
   ],
   "source": [
    "# Fazer merge para preencher timestamps faltantes com NaN\n",
    "wind_data_regularized = pd.merge(complete_df, wind_data, on='timestamp', how='left')\n",
    "\n",
    "print(\"=== Dataset Regularizado ===\")\n",
    "print(f\"Forma final: {wind_data_regularized.shape}\")\n",
    "print(f\"Total de timestamps: {len(wind_data_regularized)}\")\n",
    "print(f\"Timestamps únicos: {wind_data_regularized['timestamp'].nunique()}\")\n",
    "\n",
    "# Verificar se há duplicatas finais\n",
    "final_duplicates = wind_data_regularized.duplicated(subset=['timestamp']).sum()\n",
    "print(f\"Duplicatas finais: {final_duplicates}\")\n",
    "\n",
    "# Estatísticas de valores faltantes\n",
    "missing_stats = wind_data_regularized.isnull().sum()\n",
    "print(f\"\\nEstatísticas de valores faltantes:\")\n",
    "print(f\"Colunas com dados faltantes: {(missing_stats > 0).sum()}\")\n",
    "print(f\"Total de valores NaN: {missing_stats.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d391f283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Amostra do Dataset Final ===\n",
      "Primeiras 5 linhas:\n",
      "            timestamp  Dir-SODAR-40  W-SODAR-40  WS-SODAR-40  Dir-SODAR-50  \\\n",
      "0 2021-11-10 17:20:00          29.7        0.08         5.03          30.5   \n",
      "1 2021-11-10 17:30:00          38.1       -0.08         4.94          37.7   \n",
      "2 2021-11-10 17:40:00          41.4        0.02         4.44          42.7   \n",
      "3 2021-11-10 17:50:00          36.2        0.04         4.28          44.3   \n",
      "4 2021-11-10 18:00:00          58.9       -0.04         4.53          49.5   \n",
      "\n",
      "   W-SODAR-50  WS-SODAR-50  Dir-SODAR-60  W-SODAR-60  WS-SODAR-60  ...  \\\n",
      "0        0.03         5.53          29.2       -0.03         5.54  ...   \n",
      "1       -0.05         5.30          35.0       -0.13         5.29  ...   \n",
      "2       -0.07         5.96          41.3       -0.12         5.66  ...   \n",
      "3        0.04         4.91          45.7        0.00         5.04  ...   \n",
      "4       -0.09         5.02          44.6       -0.13         4.66  ...   \n",
      "\n",
      "   WS-SODAR-110  Dir-SODAR-120  W-SODAR-120  WS-SODAR-120  Dir-SODAR-130  \\\n",
      "0          5.79           32.8         0.09          5.71           31.4   \n",
      "1          6.06           38.2        -0.31          6.18           38.4   \n",
      "2          6.67           43.2        -0.17          6.63           42.6   \n",
      "3          6.17           46.3         0.19          6.24           45.5   \n",
      "4          5.93           39.0        -0.26          6.15           39.1   \n",
      "\n",
      "   W-SODAR-130  WS-SODAR-130  Dir-SODAR-140  W-SODAR-140  WS-SODAR-140  \n",
      "0         0.10          5.69           30.8         0.10          5.61  \n",
      "1        -0.28          6.31           38.8        -0.27          6.40  \n",
      "2        -0.17          6.66           42.0        -0.16          6.72  \n",
      "3         0.14          6.19           44.5         0.11          6.11  \n",
      "4        -0.25          6.05           39.3        -0.22          6.16  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "\n",
      "Últimas 5 linhas:\n",
      "                timestamp  Dir-SODAR-40  W-SODAR-40  WS-SODAR-40  \\\n",
      "47895 2022-10-09 07:50:00          91.3        1.01         9.27   \n",
      "47896 2022-10-09 08:00:00          91.4         NaN        11.20   \n",
      "47897 2022-10-09 08:10:00          87.3        0.04        12.00   \n",
      "47898 2022-10-09 08:20:00          82.5       -0.06        11.68   \n",
      "47899 2022-10-09 08:30:00          84.7        0.40         8.84   \n",
      "\n",
      "       Dir-SODAR-50  W-SODAR-50  WS-SODAR-50  Dir-SODAR-60  W-SODAR-60  \\\n",
      "47895          89.8        0.88        10.07          90.2        0.76   \n",
      "47896          88.5        0.36        11.74          90.2        0.32   \n",
      "47897          87.6       -0.19        12.28          85.1       -0.33   \n",
      "47898          78.6        0.02        11.93          75.6        0.08   \n",
      "47899          84.5        0.32         9.83          86.8        0.22   \n",
      "\n",
      "       WS-SODAR-60  ...  WS-SODAR-110  Dir-SODAR-120  W-SODAR-120  \\\n",
      "47895         9.90  ...         10.48           92.0         0.34   \n",
      "47896        10.98  ...         12.14           88.8         0.85   \n",
      "47897        13.10  ...         14.78           82.3        -0.09   \n",
      "47898        11.07  ...         11.65           73.5          NaN   \n",
      "47899        10.27  ...         11.11           83.3         0.50   \n",
      "\n",
      "       WS-SODAR-120  Dir-SODAR-130  W-SODAR-130  WS-SODAR-130  Dir-SODAR-140  \\\n",
      "47895         10.63           93.1         0.35          9.47           92.7   \n",
      "47896         12.35           87.9         0.82         12.59           88.1   \n",
      "47897         15.71           80.8        -0.14         15.40           79.6   \n",
      "47898         10.93           74.0          NaN         10.94           72.8   \n",
      "47899         11.59           83.9         0.54         11.79           83.3   \n",
      "\n",
      "       W-SODAR-140  WS-SODAR-140  \n",
      "47895         0.46          9.56  \n",
      "47896         0.69         12.41  \n",
      "47897        -0.09         15.90  \n",
      "47898          NaN         12.77  \n",
      "47899         0.61         12.20  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "\n",
      "Info do dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47900 entries, 0 to 47899\n",
      "Data columns (total 34 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   timestamp      47900 non-null  datetime64[ns]\n",
      " 1   Dir-SODAR-40   41204 non-null  float64       \n",
      " 2   W-SODAR-40     41257 non-null  float64       \n",
      " 3   WS-SODAR-40    41204 non-null  float64       \n",
      " 4   Dir-SODAR-50   41217 non-null  float64       \n",
      " 5   W-SODAR-50     41202 non-null  float64       \n",
      " 6   WS-SODAR-50    41217 non-null  float64       \n",
      " 7   Dir-SODAR-60   41205 non-null  float64       \n",
      " 8   W-SODAR-60     41155 non-null  float64       \n",
      " 9   WS-SODAR-60    41205 non-null  float64       \n",
      " 10  Dir-SODAR-70   41176 non-null  float64       \n",
      " 11  W-SODAR-70     41041 non-null  float64       \n",
      " 12  WS-SODAR-70    41176 non-null  float64       \n",
      " 13  Dir-SODAR-80   41118 non-null  float64       \n",
      " 14  W-SODAR-80     40980 non-null  float64       \n",
      " 15  WS-SODAR-80    41118 non-null  float64       \n",
      " 16  Dir-SODAR-90   41068 non-null  float64       \n",
      " 17  W-SODAR-90     40870 non-null  float64       \n",
      " 18  WS-SODAR-90    41068 non-null  float64       \n",
      " 19  Dir-SODAR-100  40979 non-null  float64       \n",
      " 20  W-SODAR-100    40708 non-null  float64       \n",
      " 21  WS-SODAR-100   40979 non-null  float64       \n",
      " 22  Dir-SODAR-110  40842 non-null  float64       \n",
      " 23  W-SODAR-110    40494 non-null  float64       \n",
      " 24  WS-SODAR-110   40842 non-null  float64       \n",
      " 25  Dir-SODAR-120  40639 non-null  float64       \n",
      " 26  W-SODAR-120    40235 non-null  float64       \n",
      " 27  WS-SODAR-120   40639 non-null  float64       \n",
      " 28  Dir-SODAR-130  40389 non-null  float64       \n",
      " 29  W-SODAR-130    39934 non-null  float64       \n",
      " 30  WS-SODAR-130   40389 non-null  float64       \n",
      " 31  Dir-SODAR-140  40056 non-null  float64       \n",
      " 32  W-SODAR-140    39594 non-null  float64       \n",
      " 33  WS-SODAR-140   40056 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(33)\n",
      "memory usage: 12.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Exibir amostra dos dados finais\n",
    "print(\"=== Amostra do Dataset Final ===\")\n",
    "print(\"Primeiras 5 linhas:\")\n",
    "print(wind_data_regularized.head())\n",
    "print(\"\\nÚltimas 5 linhas:\")\n",
    "print(wind_data_regularized.tail())\n",
    "print(\"\\nInfo do dataset:\")\n",
    "print(wind_data_regularized.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b5fa174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Salvo ===\n",
      "Arquivo: ../wind_data.csv\n",
      "Tamanho: 47900 registros\n",
      "Colunas: 34\n",
      "Período: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "✓ Arquivo criado com sucesso (7.75 MB)\n"
     ]
    }
   ],
   "source": [
    "# Salvar o dataset regularizado\n",
    "output_file = output_path / 'wind_data.csv'\n",
    "\n",
    "# Salvar o arquivo\n",
    "wind_data_regularized.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"=== Dataset Salvo ===\")\n",
    "print(f\"Arquivo: {output_file}\")\n",
    "print(f\"Tamanho: {len(wind_data_regularized)} registros\")\n",
    "print(f\"Colunas: {len(wind_data_regularized.columns)}\")\n",
    "print(f\"Período: {wind_data_regularized['timestamp'].min()} até {wind_data_regularized['timestamp'].max()}\")\n",
    "\n",
    "# Verificar se arquivo foi criado\n",
    "if output_file.exists():\n",
    "    file_size = output_file.stat().st_size / (1024 * 1024)  # MB\n",
    "    print(f\"✓ Arquivo criado com sucesso ({file_size:.2f} MB)\")\n",
    "else:\n",
    "    print(\"✗ Erro ao criar arquivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7848a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMO DO PROCESSAMENTO ===\n",
      "\n",
      "1. Arquivos processados: Dir.txt, W.txt, WS.txt\n",
      "2. Dataset combinado: wind_data.csv\n",
      "3. Período de dados: 2021-11-10 17:20:00 até 2022-10-09 08:30:00\n",
      "4. Intervalo: 10 minutos\n",
      "5. Total de registros: 47,900\n",
      "6. Colunas de dados: 33 (SODAR-40 até SODAR-140)\n",
      "7. Duplicatas removidas: 833\n",
      "8. Timestamps adicionados: 7042\n",
      "\n",
      "✓ Processamento concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Resumo final do processamento\n",
    "print(\"=== RESUMO DO PROCESSAMENTO ===\")\n",
    "print(f\"\\n1. Arquivos processados: {', '.join(files_to_process)}\")\n",
    "print(f\"2. Dataset combinado: wind_data.csv\")\n",
    "print(f\"3. Período de dados: {wind_data_regularized['timestamp'].min()} até {wind_data_regularized['timestamp'].max()}\")\n",
    "print(f\"4. Intervalo: 10 minutos\")\n",
    "print(f\"5. Total de registros: {len(wind_data_regularized):,}\")\n",
    "print(f\"6. Colunas de dados: {len(wind_data_regularized.columns) - 1} (SODAR-40 até SODAR-140)\")\n",
    "print(f\"7. Duplicatas removidas: {duplicates_before}\")\n",
    "print(f\"8. Timestamps adicionados: {len(complete_timeline) - len(wind_data) + duplicates_before}\")\n",
    "print(f\"\\n✓ Processamento concluído com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
